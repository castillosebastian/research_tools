{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da008236",
   "metadata": {},
   "source": [
    "# Regresion lineal: train MSE vs test MSE (*mean square prediction error*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f41fd",
   "metadata": {},
   "source": [
    "El *error cuadrático medio* es la métrica estándar para evaluar la bondad de ajuste de nuestro modelo a los datos. Es decir qué tan cerca están los valores que predice nuestro modelo para la variable *target* (o de respuesta) de ciertas observaciones respecto de los valores reales que muestra en las observaciones consideradas. La equación es: $$ MSE = \\sum_{i = 1}^{n}{(y_i - \\hat{f}(x_i))^2} $$ \n",
    "\n",
    "*The MSE will be small if the predicted responses are very close to the true responses, and will be large if for some of the observations, the predicted and true responses differ substantially.*(ISL) El error cuadrático medio se computa en primer lugar utilizando los datos de entrenamiento, por lo que -estrictamente hablando- se denomina: *error cuadrático medio de entrenamiento*. Pero, en un escenario real el error importante es aquél que arroja nuestra set de datos de *testeo*, que fueron datos no empleado al momento de entrenar nuestro modelo.Esto es así pues lo que interesa es predecir (regresar) el valor de la variable objetivo en casos *no vistos* por el modelo, es decir casos a futuro.\n",
    "\n",
    "En conclusión, queremos elegir el modelo con el menor *error cuadrático medio de testeo (test MSE)* como opuesto al *menor error cuadrático medio de entrenamiento*. Si disponemos de suficientes datos de testeo podemo computar:  $$ Ave(\\hat{f}(x_i) - x_0)^2 $$ \n",
    "\n",
    "Un aspecto a considerar para elegir el modelo es preferir aquél con el *error cuadrático promedio de predicción* más bajo posible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc7d90",
   "metadata": {},
   "source": [
    "# Overfiting, Variance y Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670938d2",
   "metadata": {},
   "source": [
    "Si se dispone de datos de testeo la elección del mejor modelo es accesible empleando test_MSE. Sin embargo, si no se dispone de datos de testeo, cuál modelo deberíamos elegir? Podríamos pensar que debemos siempre elegir aquél con menor error de entrenamiento. Pues No!. Muchas veces, modelos con buen desempeño en datos de entrenamiento arrojan resultados malos en los datos de testeo.    \n",
    "\n",
    "Pensemos lo siguiente, supongamos que podemos generar disintas lineas de regresión (a partir de distinos modelos de *f*) logrando además de la *recta de regresión lineal* otras líneas que se ajustan mejor a los  los datos de entrenamiento, siguiendo pendientes curvas. En este caso se dice que las lineas curvas tienen flexibilidad respecto de los datos de entrenamiento, aunque formalmente hablando se trata de *grados de libertad* (cantidad de sintetiza la flexibilidad de la curva de regresión). La recta de regresión lineal tiene baja flexibilidad, presenta 2 grados de libertad. A partir de ahí, a mayor flexibilidad, mayor grados de libertad, mejor ajuste a los datos de entrenamiento, un MSE más bajo. Todos contentos!? NO, pues los buenos resultados en las predicciones de entrenamiento no aseguran buenos resultados en los datos de testeo (o en el mundo real).   \n",
    "\n",
    "Cuando un modelo arroja un error de entrenamiento bajo pero un los datos de testeo muetra un error alto, decimos que el modelo está *sobreajustado* (*overfitting*) a los datos. Es decir, el modelo está identificando patrones en los datos de entrenamiento que no aparecen en los datos de testeo, y eso bien puede deberse a que los patrones presentes en los datos de entrenamiento no se vinculan a una verdadera relación definida por *f* sino simplemente a variaciones aleatorias.   \n",
    "\n",
    "Por lo dicho, la sola utilización de MSE no asegura un buen resultado de nuestro modelo. En general la evaluación debe ser más amplia, y la búsqueda del menor test_MSE debe considerar qué modelo minimiza dicho error y al mismo tiempo presenta la menor **varianza** y el menor **sesgo**. Qué significa la menor varianza y sesgo? La varianza alude a la variación que tendremos en *f* (nuestros coeficientes) de repetir el modelo en base a nuevos datos. Si la linea de nuestro modelo sigue una línea recta (no es flexible, tiene grado 2 de libertad) una variación en los datos no va a producir una variación sensible en los coeficientes, sin embargo una linea curva, flexible a los datos, sí lo hará. El sesgo por otro lado se asocia al error que es propio de nuestro modelo al intentar modelar una relación cuyo *f* nos es incognoscible. En líneas generales, modelos más flexibles presetan menor sesgo. \n",
    "\n",
    "En conclusión, como regla general, a medida que empleamos modelos más flexibles tendremos un aumento de la varianza y una disminución del sesgo. El ratio entre esas magnitudes establecerá si el MSE aumenta o disminuye. Como son magnitudes relacionadas, en generá la dinámica que presentan sigue la siguiente relacón: a medida que aumentamos la flexibilidad de un modelo el sesgo baja más rápido que el aumento de la varianza. Sin embargo en cierto punto, mayor flexibilidad no ofrece mejoras sustanciales en el sesgo y sí genera aumentos importantes en la varianza, empeorando el MSE. Esta dinámica se reconoce como ***bias-variance trade-off***."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
