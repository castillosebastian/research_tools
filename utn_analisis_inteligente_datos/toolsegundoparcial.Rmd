---
title: 'Análisis Inteligente de Datos: Segundo Parcial'
author: "Claudio Sebastián Castillo"
date: "`r format(Sys.Date(), '%d de %B de %Y') `"
output:
  pdf_document: default
  html_document:
    df_print: paged
params:
  ANOVA: no
  nombre_dataset:
    label: Seleccione nombre csv
    value: ''
    input: text
  values:
    label: Variable numerica
    input: text
    value: ''
  categories:
    label: Variable categorica o factor
    input: text
    value: ''
  ctranformacion: no
  ANOVA_multivar: no
  categorieANOVAm:
    label: Variable categorica o factor
    input: text
    value: ''
  LDA: no
  categoriesLDA:
    label: 'LDA: Variable categorica o factor'
    input: text
    value: ''
  valores_lda_nvaobs:
    label: Valores de la nueva observaciones a clasificar
    input: text
    value: ''
  QDA: no
  categoriesQDA:
    label: 'QDA: Variable categorica o factor'
    input: text
    value: ''
  valores_qda_nvaobs:
    label: Valores de la nueva observaciones a clasificar
    input: text
    value: ''
  SVM: no
  categoriesSVM:
    label: 'SVM: Variable categorica o factor'
    input: text
    value: ''
  valores_SVM_nvaobs:
    label: Valores de la nueva observaciones a clasificar
    input: text
    value: ''
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
source("Unidad0_repos_and_tools.R")

# bibliograf
# https://bookdown.org/steve_midway/DAR/understanding-anova-in-r.html _______IMPORTANTE_________
# https://rpubs.com/Miguel_Tripp/anova 
# https://www.cienciadedatos.net/documentos/19_anova.html
# https://www.cienciadedatos.net/documentos/9_homogeneidad_de_varianza_homocedasticidad.html
#https://fhernanb.github.io/Manual-de-R/ph.html#prueba-de-hip%C3%B3tesis-para-la-varianza-sigma2-de-una-poblaci%C3%B3n-normal
```

```{r, params}
ANOVA = params$ANOVA
db_name = params$nombre_dataset
variable_numerica = params$values
variable_factor = params$categories
ctranformacion = params$ctranformacion
options(scipen = 999) # inhabilito notacion científica
ANOVAm = params$ANOVA_multivar
variable_factor_anovam = params$categorieANOVAm
LDA = params$LDA
variable_factor_lda = params$categoriesLDA
if (params$valores_lda_nvaobs == ''){
  valores_lda_nvaobs <- NA
} else {
 valores_lda_nvaobs =  unlist(stringr::str_split(params$valores_lda_nvaobs, ","))
}
QDA = params$QDA
variable_factor_qda = params$categoriesQDA
if (params$valores_qda_nvaobs == ''){
  valores_qda_nvaobs <- NA
} else {
 valores_qda_nvaobs =  unlist(stringr::str_split(params$valores_qda_nvaobs, ","))
}
SVM = params$SVM
variable_factor_svm = params$categoriesSVM


```

# ANOVA 

<!-- # EJERCICIO X -->

<!-- Análisis de las medias de dos o más grupos. -->

<!-- **H0:** las medias son iguales entre los grupos . Bajo la hipótesis nula de que las observaciones de los distintos grupos proceden todas de la misma población (tienen la misma media y varianza), la varianza ponderada entre grupos será la misma que la varianza promedio dentro de los grupos. -->
<!-- **H1:** al menos dos medias son distintas del resto -->

<!-- **Requisitos:** -->

<!-- - distribuciones normales -->
<!-- - independientes entre si, y -->
<!-- - igual varianza (homosedásticas) -->

<!-- Si los supuestos no se satisface se pueden aplicar trasnformaciones para intentar aproximarnos a la normalidad en la distribución de los datos o bien aplicar técnicas no paramétricas que no tengan aquellos supuestos. -->

## Datos 

```{r, anova1, eval=ANOVA} 
dir = "~/R/research_tools/utn_analisis_inteligente_datos/"
f = glue::glue(dir, db_name)
df <- read_csv(f)
# manual enter data

```

```{r, anova2, eval=ANOVA}
str(df) 
```

```{r, anova3, eval=ANOVA}
head(df) 
```

## Observaciones por grupo:

```{r, anova4, eval=ANOVA} 
observaciones <- df %>% 
  group_by(df[[{{variable_factor}}]]) %>% 
  summarise(n())
observaciones
```


## Se cumplen los supuestos para su implementación?

<!-- **Boxplot para ver distribución de datos** -->

<!-- - Identificar asimetrías(sesgo a uno de los lados) -->
<!-- - Datos atipicos -->
<!-- - Diferencia de varianzas -->
<!-- - Homocedasticidad     -->

```{r, anova5, eval=ANOVA} 
ggplot(data = df, aes(x = df[[{{variable_factor}}]], y = df[[{{variable_numerica}}]], fill = as.factor(df[[{{variable_factor}}]])))+
 geom_boxplot()+
 geom_point(position = position_jitter(0.1))
```

<!-- **Evaluación Parcial** Existen diferencias entre las distribuciones de datos de cada organismo? ver: Las cajas no solo se ubican en rangos distintos? abarcan distintos valores según el órgano? Bajo estas condiciones deberíamos sospechar que no hay homosedasticidad. -->

<!-- **QQplots** -->

<!-- Si se tuviese una muestra distribuída perfectamente normal, se esperaría que los puntos estuviesen perfectamente alineados con la línea de referencia, sin embargo, las muestran con las que se trabajan en la práctica casi nunca presentan este comportamiento aún si fueron obtenidas de una población normal. En la práctica se aceptan alejamientos del patrón lineal para aceptar que los datos si provienen de una población normal. -->

```{r, anova6, eval=ANOVA}
ggplot(data = df, aes(sample = df[[{{variable_numerica}}]], colour = as.factor(df[[{{variable_factor}}]])))+
  stat_qq(show.legend = F)+
  stat_qq_line()+
  facet_wrap(.~ as.factor(df[[{{variable_factor}}]]))
```

## Anova

```{r, anova7, eval=ANOVA}
values = df[[{{variable_numerica}}]]
values
```

```{r, anova8, eval=ANOVA} 
# factorizo variable factor
fact = as.factor(df[[{{variable_factor}}]]) 
fact

```

### fit del modelo

```{r, anova9, eval=ANOVA} 
if(ctranformacion){
  bm = MASS::boxcox(lm(values~fact)) 
  lambda= bm$x
  lik= bm$y
  bcm=cbind(lambda,lik)
  bcm[order(lik),]
  lamvalue=bm$x[which(bm$y==max(bm$y))]
  df[[{{variable_numerica}}]] = values^lamvalue
  df_anova =  aov(values ~ fact, data = df )
} else{
  df_anova =  aov(values ~ fact, data = df )  
}
```

```{r, anova10, eval=ANOVA} 
summary(df_anova) 
```

### coeficientes

```{r, anova11, eval=ANOVA}
df_anova$coefficients
```

### p-value

```{r, anova12, eval=ANOVA}
p_value <- summary(df_anova)[[1]][1,5]
p_value
```

### F-value

```{r, anova13, eval=ANOVA}
summary(df_anova)[[1]][1,4]
```

### Plot ANOVA

```{r, anova14, eval=ANOVA}
plot(df_anova)
```

### Conclusión

```{r, anova15, , eval=ANOVA, class.output="bg-warning"}
if(p_value<0.05){'H0 debe rechazarse, al menos dos medias son distintas a nivel de significancia 0.05'} else{'No hay evidencia para rechazar H0, las medias son iguales'}

```

## Testear homosedasticidad

<!-- Test de Levene: que no es sensible a la falta de normalidad o a la presencia de valores atípicos -->

```{r, anova16, eval=ANOVA}
ltest = car::leveneTest(y = df[[{{variable_numerica}}]], group = df[[{{variable_factor}}]], center = 'median')
ltest
```

```{r, anova17, eval=ANOVA, class.output="bg-warning"}
if(ltest$`Pr(>F)`[1]<0.05){'H0 debe rechazarse: no se cumple supuesto de homosedasticidad'} else {'No hay evidencia para rechazar H0, luego los datos son homosedásticos'}
```

Test de Bartlett 

*sensibilidad al supuesto de normalidad*

```{r, anova18, eval=ANOVA}
btest = bartlett.test(df[[{{variable_numerica}}]] ~ df[[{{variable_factor}}]])
btest
```

```{r, anova19, eval=ANOVA, class.output="bg-warning"}
if(btest$p.value<0.05){'H0 debe rechazarse: no se cumple supuesto de homosedasticidad'} else {'No hay evidencia para rechazar H0, luego los datos son homosedásticos'}
```

## Testear normalidad

<!-- Si los grupos tienen mas de *50 observaciones* se emplea el test de Kolmogorov-Smirnov con la corrección de Lilliefors. Si fuesen menos de 50 eventos por grupo se emplearía el test Shapiro-Wilk. -->

```{r, anova20, eval=ANOVA, class.output="bg-warning"}

if(observaciones[[2]][[1]] > 50) {
  
  #Opcion 1 (Muestras n>=50) Lilliefors - Kolmogorov
  lillietest = lillie.test(df_anova$residuals)
  print(lillietest)
  if(lillietest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
  
} else {
  # Opcion 2 (Muestras n<=50) Shapirol - Wilks
  shapirotest = shapiro.test(residuals(df_anova))
  print(shapirotest)
  if(shapirotest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
}

```

## Testear normalidad analizando residuos

```{r, anova21, eval=ANOVA}
adtest <- nortest::ad.test(residuals(df_anova))
adtest
```

```{r, anova22, eval=ANOVA, class.output="bg-warning"}
 if(adtest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
```

```{r, anova23, eval=ANOVA}
agostinotest = moments::agostino.test(residuals(df_anova))
agostinotest
```

```{r, anova24, eval=ANOVA, class.output="bg-warning"}
 if(agostinotest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
```

# Anova y después: post-hoc

<!-- Cuando se rechaza la hipótesis nula es natural seguir la exploración para determinar cuáles medias son diferentes. Esta exploración se denominan *comparaciones a posteriori o post-hoc*. -->

## Tukey’s Honest Significant Differences (HSD)

```{r, anova25, eval=ANOVA}
TukeyHSD(df_anova)
```

```{r, anova26, eval=ANOVA}
plot(TukeyHSD(df_anova))
```

# Cuando ANOVA no funciona: test de Kruskal-Wallis

<!-- El test de Kruskal-Wallis, también conocido como test H, es la alternativa no paramétrica al test ANOVA de una vía para datos no pareados. Se trata de una extensión del test de Mann-Whitney para más de dos grupos. Es por lo tanto de un test que emplea rangos para contrastar la hipótesis de que k muestras han sido obtenidas de una misma población. -->

<!-- A diferencia del ANOVA en el que se comparan medias, el test de Kruskal-Wallis contrasta si las diferentes muestras están equidistribuidas y que por lo tanto pertenecen a una misma distribución (población). Bajo ciertas simplificaciones puede considerarse que el test de Kruskal-Wallis compara las medianas. -->

<!-- H0: todas las muestras provienen de la misma población (distribución).     -->
<!-- HA: Al menos una muestra proviene de una población con una distribución distinta  -->

```{r, anova27, eval=ANOVA}
kruskaltest = kruskal.test( values ~ fact, data = df)
kruskaltest
```

```{r, anova28, eval=ANOVA, class.output="bg-warning"}
 if(kruskaltest$p.value<0.05){'H0 debe rechazarse: se encuentra significancia en la diferencia de al menos dos grupos'} else {'No hay evidencia para rechazar H0'}
```

```{r, anova29, eval=ANOVA}
#pairwise.wilcox.test(x = values, g = fact, p.adjust.method = "holm" )
pgirmess::kruskalmc(values ~ fact)
```


# ANOVA_multivariante 

## Datos
```{r, eval=ANOVAm}
# subject <- as.factor(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
#                        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30))
sex <- c("female", "male", "male", "female", "male", "male", "male", "female",
         "female", "male", "male", "male", "male", "female", "female", "female",
         "male", "female", "female", "male", "male", "female", "male", "male",
         "male", "male", "male", "male", "female", "male" )
age <- c("adult", "adult", "adult", "adult", "adult", "adult", "young", "young",
         "adult", "young", "young", "adult", "young", "young", "young", "adult",
         "young", "adult", "young", "young", "young", "young", "adult", "young",
         "young", "young", "young", "young", "young", "adult")
result <- c(7.1, 11.0, 5.8, 8.8, 8.6, 8.0, 3.0, 5.2, 3.4, 4.0, 5.3, 11.3, 4.6, 6.4,
            13.5, 4.7, 5.1, 7.3, 9.5, 5.4, 3.7, 6.2, 10.0, 1.7, 2.9, 3.2, 4.7, 4.9,
            9.8, 9.4)

datos <- data.frame(#subject,
                    sex, age, result)

datos[[{{variable_factor_anovam}}]] = as.integer(datos[[{{variable_factor_anovam}}]])
                                             
head(datos, 4)
```
## Gafico

```{r, eval=ANOVAm}
ggplot(data = datos, mapping = aes(x = age, y = result, colour = sex)) +
   geom_boxplot() +
   theme_bw()

```

## Test Anovam

```{r, eval=ANOVAm}
anova_2vias <- aov(formula = result ~ sex*age, data = datos)
s = summary(anova_2vias)
s
```

```{r, eval=ANOVAm, class.output="bg-warning"}
if(any(s[[1]][["Pr(>F)"]] < 0.05)){'La varianza presenta diferencias significativas entre los grupos'} else {'La varianza no presenta diferencia significativa entre los grupos'}
```
## Tamaño del efecto

.01: Small effect size
.06: Medium effect size
.14 or higher: Large effect size

```{r, eval=ANOVAm}
efecto = lsr::etaSquared(anova_2vias)
efecto
```

```{r, eval= ANOVAm}
efecto_medio = rownames(efecto)[efecto[,1] >= 0.06 & efecto[,1] < 0.14 ] 
if(length(efecto_medio) >=1){str_c('efecto medio en:', efecto_medio)} else {'No hay efecto medio'}
```

```{r, eval= ANOVAm}
efecto_grande = rownames(efecto)[efecto[,1] >= 0.14]
if(length(efecto_grande) >=1){str_c('Efecto grande en:', efecto_grande)} else {'No hay efecto grande'}
```

# Analisis Discriminante Lineal (LDA) 

```{r}
# artículo: https://www.cienciadedatos.net/documentos/28_linear_discriminant_analysis_lda_y_quadratic_discriminant_analysis_qda#Ejemplo_datos_insectos
```


<!-- El Análisis Discriminante Lineal o Linear Discrimiant Analysis (LDA) es un método de clasificación supervisado de variables cualitativas en el que dos o más grupos son conocidos a priori y nuevas observaciones se clasifican en uno de ellos en función de sus características. -->

<!-- Tres enfoques: -->
<!-- - x verosimilitud/Fisher -->
<!--     Implica tener un modelo de los datos donde se pueda establecer una línea de discriminación entre grupos. El problema se puede plantear como  -->
<!--     la busqueda de maximizar la variabilidad entre los grupos en relacion al total de la varianza en los datos. En termino matriciales esto implica     -->
<!--     la busqueda de proyectar las observaciones p-variadas sobre una dirección que maximice la separaciones entre los grupos. Parecido a PCA. -->
<!-- - x distancia Mahalanobis -->
<!-- - x Bayes/probabilidad a_posteriori -->

<!-- # Requisitos    -->

<!-- - Cada predictor que forma parte del modelo se distribuye de forma normal en cada una de las clases de la variable respuesta. En el caso de múltiples predictores, las observaciones siguen una distribución normal multivariante en todas las clases.    -->

<!-- - La varianza del predictor es igual en todas las clases de la variable respuesta. En el caso de múltiples predictores, la matriz de covarianza es igual en todas las clases. Si esto no se cumple se recurre a Análisis Discriminante Cuadrático (QDA).     -->


<!-- # LDA_1predictor vs LDA_multiples_predictores -->

<!-- La diferencia reside en que X, en lugar de ser un único valor, es un vector formado por el valor de p predictores X=(X1,X2,...,X3) y que, en lugar de proceder de una distribución normal, procede de una distribución normal multivariante. -->

<!-- Un vector sigue una distribución k-normal multivariante si cada uno de los elementos individuales que lo forman sigue una distribución normal y lo mismo para toda combinación lineal de sus k elementos. -->

<!-- # LDA vs Regresion Logística -->

<!-- Es una alternativa a la regresión logística cuando la variable cualitativa tiene más de dos niveles. Si bien existen extensiones de la regresión logística para múltiples clases, el LDA presenta una serie de ventajas: -->

<!-- - Si las clases están bien separadas, los parámetros estimados en el modelo de regresión logística son inestables. El método de LDA no sufre este problema.     -->
<!-- - Si el número de observaciones es bajo y la distribución de los predictores es aproximadamente normal en cada una de las clases, LDA es más estable que la regresión logística.    -->

## Datos

```{r, eval=LDA}
input <- ("
especie pata abdomen organo_sexual 
a 191 131 53
a 185 134 50
a 200 137 52
a 173 127 50
a 171 128 49
a 160 118 47
a 188 134 54
a 186 129 51
a 174 131 52
a 163 115 47
b 186 107 49
b 211 122 49
b 201 144 47
b 242 131 54
b 184 108 43
b 211 118 51
b 217 122 49
b 223 127 51
b 208 125 50
b 199 124 46
")
datos <- read.table(textConnection(input), header = TRUE)
#datos = iris
# factorizo variable factor
datos[[{{variable_factor_lda}}]] = as.factor(datos[[{{variable_factor_lda}}]]) 
# resumente datos
str(datos)
```

```{r, eval=LDA}
temp <- datos %>% select(!{{variable_factor_lda}})
l <- length(unique(datos[[{{variable_factor_lda}}]]))

```

## Explorando discriminación por pares de variable

```{r, eval=LDA}
pairs(x =temp, col =datos[[{{variable_factor_lda}}]], oma=c(3,3,3,15))
par(xpd = TRUE)
legend("bottomright", fill = unique(datos[[{{variable_factor_lda}}]]), legend = c(levels(datos[[{{variable_factor_lda}}]])))
```

<!-- Ver qué par de variables separa bien las `r variable_factor_lda ` -->

## Homogeneidad de la Varianza: Histograma VariablexGrupo

```{r, eval=LDA}
par(mfcol = c(l, dim(temp)[2]))

for (k in 1:dim(temp)[2]) {
  j0 <- names(temp)[k]
  x0 <- seq(min(temp[, k]), max(temp[, k]), le = 50)
  for (i in 1:l) {
    i0 <- levels(datos[[{{variable_factor_lda}}]])[i]
    x <- temp[datos[[{{variable_factor_lda}}]] == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste(variable_factor_lda, i0),
    xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

## Contraste de Normalidad Univariante Shapiro-Wilk

```{r, eval=LDA}
datos_tidy <- melt(datos, value.name = "valor")
datos_tidy_test <- datos_tidy %>% group_by(datos_tidy[[{{variable_factor_lda}}]], variable) %>% summarise(p_value_Shapiro.test = round(shapiro.test(valor)$p.value, digits = 5))
kableExtra::kable(datos_tidy_test)
```

```{r, eval=LDA, class.output="bg-warning"}
if(any(datos_tidy_test$p_value_Shapiro.test < 0.05)){'H0 debe rechazarse: hay evidencia de falta de normalidad en los siguientes casos'} else {'No hay evidencia de falta de normalidad univariante en ninguna variable predictora por grupo'}
datos_tidy_test[datos_tidy_test$p_value_Shapiro.test < 0.05, ]

```

## Contraste de Normalidad MultiVariante

### Outliers

```{r, eval=LDA}
outliers <- mvn(data =temp, mvnTest = "hz", multivariateOutlierMethod = "quan")
```

### Test de Royston

```{r, eval=LDA}
royston_test <- mvn(data = temp, mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
```

```{r, eval=LDA, class.output="bg-warning"}
# N tiene que ser > 3 y < a 5000
if(any(royston_test$multivariateNormality$MVN == "NO")){'H0 debe rechazarse: falta de normalidad multivariante a nivel de significancia 0.05'} else {'No hay evidencia de falta de normalidad multivariante a nivel de significancia 0.05'}
```

### Test de Henze-Zirkler

```{r, eval=LDA}
hz_test <- mvn(data = temp, mvnTest = "hz")
hz_test$multivariateNormality
```

```{r, eval=LDA, class.output="bg-warning"}
if(any(hz_test$multivariateNormality$MVN == "NO")){'H0 debe rechazarse: falta de normalidad multivariante a nivel de significancia 0.05'} else {'No hay evidencia de falta de normalidad multivariante a nivel de significancia 0.05 '}
```

## Contraste de Matriz de Covarianza

```{r, eval=LDA}
library(biotools)
boxmtest =  boxM(data = temp, grouping = datos[[{{variable_factor_lda}}]])
boxmtest
```

```{r, eval=LDA, class.output="bg-warning"}
if(boxmtest$p.value < 0.05){'H0 debe rechazarse: hay evidencia de que la covarianza no es igual en todos los grupos'} else {'Se puede aceptar que la matriz de covarianza es igual en todos los grupos'}
```

## Estimación de parámetros de la función de densidad (u^(X),E) y cálculo de la función discriminante según aproximación de Fisher via lda()

```{r, eval = LDA}
modelo_lda <- lda(temp, datos[[{{variable_factor_lda}}]])
```

```{r, eval= LDA}
modelo_lda
```

`r if (LDA & !is.na(valores_lda_nvaobs)) '## Clasificacion de la nueva observacion'`

```{r, eval= LDA & !is.na(valores_lda_nvaobs)}
columnas = colnames(temp)
nueva_observacion <- rbind(columnas, valores_lda_nvaobs)
nueva_observacion <- nueva_observacion %>% 
  janitor::row_to_names(row_number = 1)
nueva_observacion <- nueva_observacion %>% as_tibble() %>% mutate_if(is.character, as.numeric)
predict(object = modelo_lda, newdata = nueva_observacion)
```

<!-- El resultado muestra, según la función discriminante, la probabilidad posterior por grupo -->

## Evaluación del error: Accuracy Table

```{r, eval=LDA}
predicciones <- predict(object = modelo_lda, newdata = temp, method = "predictive")

table(datos[[{{variable_factor_lda}}]], predicciones$class, dnn = c("Clase real", "Clase predicha"))


```

```{r, eval=LDA}
trainig_error <- mean(datos[[{{variable_factor_lda}}]] != predicciones$class) * 100
paste("trainig_error =", trainig_error, "%")
```

## Visualización de las clasificaciones

```{r, eval=LDA}
partimat(temp, datos[[{{variable_factor_lda}}]], method = "lda", prec = 200)
```

# Analisis Discriminante Cuadrático (QDA)>falta de homocedasticidad/outliers LDA 

<!-- El clasificador cuadrático o Quadratic Discriminat Analysis QDA se asemeja en gran medida al LDA, con la única diferencia de que el QDA considera que cada clase k tiene su propia matriz de covarianza (∑k) y, como consecuencia, la función discriminante toma forma cuadrática.    -->
<!-- QDA genera límites de decisión curvos por lo que puede aplicarse a situaciones en las que la separación entre grupos no es lineal.    -->

```{r, eval = QDA}
library(mclust)
datosQ = as_tibble(mclust::banknote)
#se recodifican las clases de la variable Status: verdadero = 0, falso = 1

# factorizo variable factor
datosQ[[{{variable_factor_qda}}]] = as.factor(datosQ[[{{variable_factor_qda}}]])
# resumente datos
str(datosQ)
```

```{r, eval = QDA}
temp <- datosQ %>% dplyr::select(!{{variable_factor_qda}})
l <- length(unique(datosQ[[{{variable_factor_qda}}]]))
```

## Explorando discriminación por pares de variable

```{r, eval=QDA}
pairs(x =temp, col =datosQ[[{{variable_factor_qda}}]], oma=c(3,3,3,15))
par(xpd = TRUE)
legend("bottomright", fill = unique(datosQ[[{{variable_factor_qda}}]]), legend = c(levels(datosQ[[{{variable_factor_qda}}]])))
```

## Contraste de Normalidad Univariante Shapiro-Wilk

```{r, eval=QDA}
datosQ_tidy <- melt(datosQ, value.name = "valor")
datosQ_tidy_test <- datosQ_tidy %>% group_by(datosQ_tidy[[{{variable_factor_qda}}]], variable) %>% summarise(p_value_Shapiro.test = round(shapiro.test(valor)$p.value, digits = 5))
kableExtra::kable(datosQ_tidy_test)
```

```{r, eval=QDA, class.output="bg-warning"}
if(any(datosQ_tidy_test$p_value_Shapiro.test < 0.05)){'H0 debe rechazarse: hay evidencia de falta de normalidad en los siguientes casos'} else {'No hay evidencia de falta de normalidad univariante en ninguna variable predictora por grupo'}
datosQ_tidy_test[datosQ_tidy_test$p_value_Shapiro.test < 0.05, ]

```

## Contraste de Normalidad MultiVariante

### Outliers

```{r, eval=QDA}
outliers <- MVN::mvn(data = temp, mvnTest = "hz", multivariateOutlierMethod = "quan")
```

### Test de Royston

```{r, eval=QDA}
royston_test <- MVN::mvn(data = temp, mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality
```

```{r, eval=QDA, class.output="bg-warning"}
# N tiene que ser > 3 y < a 5000
if(any(royston_test$multivariateNormality$MVN == "NO")){'H0 debe rechazarse: falta de normalidad multivariante a nivel de significancia 0.05'} else {'No hay evidencia de falta de normalidad multivariante a nivel de significancia 0.05'}
```

### Test de Henze-Zirkler

```{r, eval=QDA}
hz_test <- MVN::mvn(data = temp, mvnTest = "hz")
hz_test$multivariateNormality
```

```{r, eval=QDA, class.output="bg-warning"}
if(any(hz_test$multivariateNormality$MVN == "NO")){'H0 debe rechazarse: falta de normalidad multivariante a nivel de significancia 0.05'} else {'No hay evidencia de falta de normalidad multivariante a nivel de significancia 0.05 '}
```

## Contraste de Matriz de Covarianza

```{r, eval=QDA}
library(biotools)
boxmtest =  biotools::boxM(data = temp, grouping = datosQ[[{{variable_factor_qda}}]])
boxmtest
```

```{r, eval=QDA, class.output="bg-warning"}
if(boxmtest$p.value < 0.05){'H0 debe rechazarse: hay evidencia de que la covarianza no es igual en todos los grupos'} else {'Se puede aceptar que la matriz de covarianza es igual en todos los grupos'}
```

## Parámetros de la función de densidad  función discriminante según aproximación de Fisher via qda()

```{r, eval = QDA}
modelo_qda <- qda(temp, datosQ[[{{variable_factor_qda}}]])
```

```{r, eval= QDA}
modelo_qda
```

`r if (QDA & !is.na(valores_qda_nvaobs)) '## Clasificacion de la nueva observacion'`

```{r, eval= QDA & !is.na(valores_qda_nvaobs)}
columnas = colnames(temp)
nueva_observacion <- rbind(columnas, valores_qda_nvaobs)
nueva_observacion <- nueva_observacion %>% 
  janitor::row_to_names(row_number = 1)
nueva_observacion <- nueva_observacion %>% as_tibble() %>% mutate_if(is.character, as.numeric)
predict(object = modelo_qda, newdata = nueva_observacion)
```

<!-- El resultado muestra, según la función discriminante, la probabilidad posterior por grupo -->

## Evaluación del error: Accuracy Table

```{r, eval=QDA}
predicciones <- predict(object = modelo_qda, newdata = temp, method = "predictive")

table(datosQ[[{{variable_factor_qda}}]], predicciones$class,
      dnn = c("Clase real", "Clase predicha"))


```

```{r, eval=QDA}
trainig_error <- mean(datosQ[[{{variable_factor_qda}}]] != predicciones$class) * 100
paste("trainig_error =", trainig_error, "%")
```

## Visualización de las clasificaciones

```{r, eval=QDA}
partimat(temp, datosQ[[{{variable_factor_qda}}]], method = "qda", prec = 200)
```



# Analisis Discriminante Cuadrático Robusto (RQDA)>falta normalidad    

<!-- -emplea distancia de Mahalanobis robusta -->
<!-- -se obtiene con MCD: Minimum Covariance Determinant -->
<!-- Utilizar librería: https://github.com/valentint/rrcov  o libro alicia p.321 -->
    
# Máquinas de Soporte Vectorial

<!-- El algoritmo de las SVM a partir del producto escalar de dos vectores multidimensionales, busca una familia de hiperplanos que sepa ren los grupos. La función que define este producto escalar es denominada kernel y la misma puede ser lineal, polinómica, radial o sigmoidal. -->

<!-- Muy importante estandarizar datos -->

## Datos

```{r, eval=SVM}
# Bibliograf

# https://www.cienciadedatos.net/documentos/34_maquinas_de_vector_soporte_support_vector_machines

#Cambiar
datos <- ISLR::OJ

datos[[{{variable_factor_svm}}]] = as.factor(datos[[{{variable_factor_svm}}]])

# Convierto variables predictoras tipo factor a numeric
dat_f = datos %>% select(variable_factor_svm)
dat_all =  datos %>%
  select(-variable_factor_svm) %>%
  mutate_if(is.factor, as.numeric)

datos = dat_f %>% bind_cols(dat_all)

# x=c(rnorm (50,5,2),rnorm(50,8,1.5),rnorm(50,1,1.2))
# y=c(abs(rnorm(50,5,2)),rnorm(50,8,1.5),rnorm(50,1,1.2))
# Grupo=as.factor(c(rep("A",50),rep("B",50),rep("C",50)))
# datos =data.frame(x,y,Grupo)

# # Programar la elección de otros kernel???!!!!
# kernel = "radial" 

# resumente datos
str(datos)
```

## Grafico datos

```{r, eval=SVM}
datos %>% 
  ggplot( aes(x = variable_factor_svm, y = ..count.., fill = datos[[{{variable_factor_svm}}]])) +
  geom_bar() 
```

```{r, eval=SVM}
# Índices observaciones de entrenamiento
set.seed(123)
train <- createDataPartition(y = datos[[{{variable_factor_svm}}]], p = 0.8, list = FALSE, times = 1)
# Datos entrenamiento
datos_train <- datos[train, ]
datos_test <- datos[-train, ]
dim(datos_train)
dim(datos_test)

```

## Busqueda de mejor hiperparametro C (coste)

<!-- A la hora de ajustar un support vector classifier, es importante tener en cuenta que el hiperparámetro C (cost) controla el equilibrio bias-varianza y la capacidad predictiva del modelo, ya que determina la severidad permitida respecto a las violaciones sobre el margen. En otras palabras, necesitamos fijar un margen de separación entre observaciones a priori. Por ello es recomendable evaluar distintos valores del mismo mediante validación cruzada y escoger el valor óptimo. -->

```{r, eval=SVM}
temp = datos_train %>% select(-variable_factor_svm)
set.seed(325)
tuning <- tune(svm, train.x = temp,  train.y = datos_train[[{{variable_factor_svm}}]],
               kernel = "linear",
               ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 15, 20)),
               scale = TRUE)
```

```{r, eval=SVM}
summary(tuning)
```

### Mejor modelo según hiperparametro

```{r, eval=SVM}
modelo_svc <- tuning$best.model
summary(modelo_svc)
```

```{r, eval=SVM}
# Muestra de 50 de los 345
head(modelo_svc$index)
```

## Predicciones del Modelo 

```{r, eval=SVM}
temp = datos_test %>% select(-variable_factor_svm)
predicciones = predict(modelo_svc, temp)
table(prediccion = predicciones, real = datos_test[[{{variable_factor_svm}}]])
```

```{r, eval=SVM}
paste("Observaciones de test mal clasificadas:", 
      100 * mean(datos_test[[{{variable_factor_svm}}]] != predicciones) %>% 
        round(digits = 4), "%")
```

# Regresión logística LR

