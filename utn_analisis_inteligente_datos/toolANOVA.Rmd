---
title: "Anova"
author: "Área de Planificación Gestión y Estadística"
date: "21/3/2022"
output: html_document
params:
  nombre_dataset:
    label: "Seleccione nombre csv"
    value: ""
    input: text
  values:
    label: 'Variable numerica'
    input: text
    value: ""
  categories:
    label: 'Variable categorica o factor'
    input: text
    value: ""
  ctranformacion: FALSE
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
#source("Unidad0_repos_and_tools.R")
library(readr)
library(dplyr)
library(ggplot2)
library(nortest)
library(moments)

# library('FactoMineR')
# bibliograf
# https://bookdown.org/steve_midway/DAR/understanding-anova-in-r.html _______IMPORTANTE_________
# https://rpubs.com/Miguel_Tripp/anova 
# https://www.cienciadedatos.net/documentos/19_anova.html
# https://www.cienciadedatos.net/documentos/9_homogeneidad_de_varianza_homocedasticidad.html
#https://fhernanb.github.io/Manual-de-R/ph.html#prueba-de-hip%C3%B3tesis-para-la-varianza-sigma2-de-una-poblaci%C3%B3n-normal
```

```{r}
db_name = params$nombre_dataset
variable_numerica = params$values
variable_factor = params$categories
ctranformacion = params$ctranformacion
options(scipen = 999) # inhabilito notacion científica

```

# Intro

Análisis de las medias de dos o más grupos.

**H0:** las medias son iguales entre los grupos . Bajo la hipótesis nula de que las observaciones de los distintos grupos proceden todas de la misma población (tienen la misma media y varianza), la varianza ponderada entre grupos será la misma que la varianza promedio dentro de los grupos.
**H1:** al menos dos medias son distintas del resto

**Requisitos:**

- distribuciones normales
- independientes entre si, y
- igual varianza (homosedásticas)

Si los supuestos no se satisface se pueden aplicar trasnformaciones para intentar aproximarnos a la normalidad en la distribución de los datos o bien aplicar técnicas no paramétricas que no tengan aquellos supuestos.

## Datos 

```{r}
dir = "~/R/research_tools/utn_analisis_inteligente_datos/"
f = glue::glue(dir, db_name)
df <- read_csv(f)
# manual enter data

```

```{r}
str(df) 
```

Head:

```{r}
head(df) 
```

Observaciones por grupo:

```{r}
observaciones <- df %>% 
  group_by(df[[{{variable_factor}}]]) %>% 
  summarise(n())

observaciones
```


## Se cumplen los supuestos para su implementación?

**Boxplot para ver distribución de datos**

- Identificar asimetrías(sesgo a uno de los lados)
- Datos atipicos
- Diferencia de varianzas
- Homocedasticidad    

```{r}
ggplot(data = df, aes(x = df[[{{variable_factor}}]], y = df[[{{variable_numerica}}]], fill = as.factor(df[[{{variable_factor}}]])))+
 geom_boxplot()+
 geom_point(position = position_jitter(0.1))
```

**Evaluación Parcial** Existen diferencias entre las distribuciones de datos de cada organismo? ver: Las cajas no solo se ubican en rangos distintos? abarcan distintos valores según el órgano? Bajo estas condiciones deberíamos sospechar que no hay homosedasticidad.

**QQplots**

Si se tuviese una muestra distribuída perfectamente normal, se esperaría que los puntos estuviesen perfectamente alineados con la línea de referencia, sin embargo, las muestran con las que se trabajan en la práctica casi nunca presentan este comportamiento aún si fueron obtenidas de una población normal. En la práctica se aceptan alejamientos del patrón lineal para aceptar que los datos si provienen de una población normal.

```{r}
ggplot(data = df, aes(sample = df[[{{variable_numerica}}]], colour = as.factor(df[[{{variable_factor}}]])))+
  stat_qq(show.legend = F)+
  stat_qq_line()+
  facet_wrap(.~ as.factor(df[[{{variable_factor}}]]))
```


## Anova

```{r}
values = df[[{{variable_numerica}}]]
values

```

```{r}
# factorizo variable factor
fact = as.factor(df[[{{variable_factor}}]]) 
fact

```

### fit del modelo

```{r}
if(ctranformacion){
  bm = MASS::boxcox(lm(values~fact)) 
  lambda= bm$x
  lik= bm$y
  bcm=cbind(lambda,lik)
  bcm[order(lik),]
  lamvalue=bm$x[which(bm$y==max(bm$y))]
  df[[{{variable_numerica}}]] = values^lamvalue
  df_anova =  aov(values ~ fact, data = df )
} else{
  df_anova =  aov(values ~ fact, data = df )  
}
```

```{r}
summary(df_anova)
```

### coeficientes

```{r}
df_anova$coefficients
```

### p-value

```{r}
p_value <- summary(df_anova)[[1]][1,5]
p_value
```

### F-value

```{r}
summary(df_anova)[[1]][1,4]
```

### Plot ANOVA

```{r}
plot(df_anova)
```

### Conclusión

```{r, class.output="bg-warning"}
if(p_value<0.05){'H0 debe rechazarse, al menos dos medias son distintas a nivel de significancia 0.05'} else{'No hay evidencia para rechazar H0, las medias son iguales'}

```

## Testear homosedasticidad

Test de Levene

*que no es sensible a la falta de normalidad o a la presencia de valores atípicos*

```{r}
ltest = car::leveneTest(y = df[[{{variable_numerica}}]], group = df[[{{variable_factor}}]], center = 'median')
ltest
```

```{r, class.output="bg-warning"}
if(ltest$`Pr(>F)`[1]<0.05){'H0 debe rechazarse: no se cumple supuesto de homosedasticidad'} else {'No hay evidencia para rechazar H0, luego los datos son homosedásticos'}
```

Test de Bartlett 

*sensibilidad al supuesto de normalidad*

```{r}
btest = bartlett.test(df[[{{variable_numerica}}]] ~ df[[{{variable_factor}}]])
btest
```

```{r, class.output="bg-warning"}
if(btest$p.value<0.05){'H0 debe rechazarse: no se cumple supuesto de homosedasticidad'} else {'No hay evidencia para rechazar H0, luego los datos son homosedásticos'}
```

## Testear normalidad

Si los grupos tienen mas de *50 observaciones* se emplea el test de Kolmogorov-Smirnov con la corrección de Lilliefors. Si fuesen menos de 50 eventos por grupo se emplearía el test Shapiro-Wilk.

```{r, class.output="bg-warning"}

if(observaciones[[2]][[1]] > 50) {
  
  #Opcion 1 (Muestras n>=50) Lilliefors - Kolmogorov
  lillietest = lillie.test(df_anova$residuals)
  print(lillietest)
  if(lillietest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
  
} else {
  # Opcion 2 (Muestras n<=50) Shapirol - Wilks
  shapirotest = shapiro.test(residuals(df_anova))
  print(shapirotest)
  if(shapirotest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
}

```

## Testear normalidad analizando residuos

```{r}
adtest <- nortest::ad.test(residuals(df_anova))
adtest
```

```{r, class.output="bg-warning"}
 if(adtest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
```

```{r}
agostinotest = moments::agostino.test(residuals(df_anova))
agostinotest
```


```{r, class.output="bg-warning"}
 if(agostinotest$p.value<0.05){'H0 debe rechazarse: no hay normalidad'} else {'No hay evidencia para rechazar H0, luego los datos son normales'}
```

# Anova y después: post-hoc

Cuando se rechaza la hipótesis nula es natural seguir la exploración para determinar cuáles medias son diferentes. Esta exploración se denominan *comparaciones a posteriori o post-hoc*.

## Tukey’s Honest Significant Differences (HSD)

```{r}
TukeyHSD(df_anova)
```

```{r}
plot(TukeyHSD(df_anova))
```

# Cuando ANOVA no funciona

El test de Kruskal-Wallis, también conocido como test H, es la alternativa no paramétrica al test ANOVA de una vía para datos no pareados. Se trata de una extensión del test de Mann-Whitney para más de dos grupos. Es por lo tanto de un test que emplea rangos para contrastar la hipótesis de que k muestras han sido obtenidas de una misma población.

A diferencia del ANOVA en el que se comparan medias, el test de Kruskal-Wallis contrasta si las diferentes muestras están equidistribuidas y que por lo tanto pertenecen a una misma distribución (población). Bajo ciertas simplificaciones puede considerarse que el test de Kruskal-Wallis compara las medianas.

H0: todas las muestras provienen de la misma población (distribución).    
HA: Al menos una muestra proviene de una población con una distribución distinta 

```{r}
kruskaltest = kruskal.test( values ~ fact, data = df)
kruskaltest
```


```{r, class.output="bg-warning"}
 if(kruskaltest$p.value<0.05){'H0 debe rechazarse: se encuentra significancia en la diferencia de al menos dos grupos'} else {'No hay evidencia para rechazar H0'}
```

```{r}
#pairwise.wilcox.test(x = values, g = fact, p.adjust.method = "holm" )
pgirmess::kruskalmc(values ~ fact)
```




